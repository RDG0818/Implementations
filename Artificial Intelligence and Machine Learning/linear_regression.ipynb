{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Linear regression models the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data.\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{X\\beta} \n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $n$: amount of observations\n",
    "- $p$: amount of features\n",
    "- $\\mathbf{y} \\in \\mathbb{R}^{n \\times 1}$: observed outputs/target vector\n",
    "- $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$: feature matrix (rows are observations, column are feature, includes column of 1s for intercept)\n",
    "- $\\mathbf{\\beta} \\in \\mathbb{R}^{p \\times 1}$: coefficient vector/parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "Y = np.array(diabetes.target)\n",
    "X = np.concatenate((df.to_numpy(), np.ones((df.shape[0], 1))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares Method\n",
    "The Least Squares Method analytically minimizes the cost function, or the sum of squared errors (residuals):\n",
    "\n",
    "$$\n",
    "J(\\beta) = ||\\mathbf{y - X\\beta}||^2 = (\\mathbf{y - X\\beta})^{\\top}(\\mathbf{y - X\\beta})\n",
    "$$\n",
    "\n",
    "Derivation:\n",
    "$$\n",
    "J(\\beta) = \\mathbf{y^{\\top}y} - 2 \\mathbf{\\beta^{\\top}X^{\\top}y} + \\mathbf{\\beta^{\\top}X^{\\top}X\\beta} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_{\\beta}\\mathbf{J} = -2\\mathbf{X^{\\top}y} + 2\\mathbf{X^{\\top}X\\beta}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{2X^{\\top}y+2X^{\\top}X\\beta} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{X^{\\top}X\\beta=X^{\\top}y}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta = \\mathbf{(X^{\\top}X)^{-1}X^{\\top}y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares Coefficents:\n",
      "beta 1: -10.01\n",
      "beta 2: -239.816\n",
      "beta 3: 519.846\n",
      "beta 4: 324.385\n",
      "beta 5: -792.176\n",
      "beta 6: 476.739\n",
      "beta 7: 101.043\n",
      "beta 8: 177.063\n",
      "beta 9: 751.274\n",
      "beta 10: 67.627\n",
      "Least Squares Intercept: 152.133 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "beta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "print(\"Least Squares Coefficents:\")\n",
    "for i in range(1, 11):\n",
    "    print(f\"beta {i}: {round(beta[i-1], 3)}\")\n",
    "print(\"Least Squares Intercept:\", round(beta[-1], 3), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Method\n",
    "The Gradient Descent Method minimizes the cost function by iteratively updating the parameters in the direction of the negative gradient:\n",
    "\n",
    "$$\n",
    "J(\\beta) = \\frac{1}{2n}||\\mathbf{y - X\\beta}||^2 \n",
    "$$\n",
    "\n",
    "$$\n",
    "J(\\beta) = \\frac{1}{2n}(\\mathbf{y - X\\beta})^{\\top}(\\mathbf{y - X\\beta})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_{\\beta}J = \\frac{1}{2n}\\nabla_{\\beta}[\\mathbf{y^{\\top}y}-2\\mathbf{\\beta^{\\top}X^{\\top}y+\\beta^{\\top}X^{\\top}X\\beta}]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_{\\beta}J = \\frac{1}{2n}[-2\\mathbf{X^{\\top}y}+2\\mathbf{X^{\\top}X\\beta}]=\\frac{1}{n}\\mathbf{X^{\\top}}\\mathbf{(X\\beta-y)}\n",
    "$$\n",
    "\n",
    "Update Rule:\n",
    "$$\n",
    "\\beta^{(t+1)}=\\beta^{t}-\\alpha\\nabla_{\\beta}J\n",
    "$$\n",
    "Where:\n",
    "- $\\alpha$ is the learning rate\n",
    "- $t$ is the current iteration\n",
    "- $\\nabla_{\\beta}J=\\frac{1}{n}\\mathbf{X^{\\top}}\\mathbf{(X\\beta-y)}$\n",
    "- $||\\beta^{(t+1)}-\\beta^{t}||_2<\\epsilon$ is the stopping condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta 1: -10.009\n",
      "beta 2: -239.815\n",
      "beta 3: 519.848\n",
      "beta 4: 324.384\n",
      "beta 5: -791.99\n",
      "beta 6: 476.591\n",
      "beta 7: 100.96\n",
      "beta 8: 177.039\n",
      "beta 9: 751.204\n",
      "beta 10: 67.627\n",
      "Least Squares Intercept: 152.133 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "beta = np.zeros((X.shape[1]))\n",
    "prev = np.ones_like(beta)\n",
    "alpha = 1.97 # manually tuned\n",
    "epsilon = 1e-5\n",
    "iterations = 0\n",
    "while (np.linalg.norm(beta - prev) > epsilon):\n",
    "    prev = beta.copy()\n",
    "    beta -= alpha * 1/X.shape[0] * X.T @ (X @ beta - Y) \n",
    "for i in range(1, 11):\n",
    "    print(f\"beta {i}: {round(beta[i-1], 3)}\")\n",
    "print(\"Least Squares Intercept:\", round(beta[-1], 3), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution from Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta 1: -10.01\n",
      "beta 2: -239.816\n",
      "beta 3: 519.846\n",
      "beta 4: 324.385\n",
      "beta 5: -792.176\n",
      "beta 6: 476.739\n",
      "beta 7: 101.043\n",
      "beta 8: 177.063\n",
      "beta 9: 751.274\n",
      "beta 10: 67.627\n",
      "Least Squares Intercept: 152.133 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(df, Y)\n",
    "coef = model.coef_\n",
    "intercept = model.intercept_\n",
    "for i in range(1, 11):\n",
    "    print(f\"beta {i}: {round(coef[i-1], 3)}\")\n",
    "print(\"Least Squares Intercept:\", round(intercept, 3), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
